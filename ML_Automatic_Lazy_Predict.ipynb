** Loading Data From Gihub repository**

!git clone https://github.com/mironjee51300/VIRUSTEXTCODE.git

** Adding Google Drive Folder Path **

import os

# Specify the path to the folder you want to inspect
# For the current directory, you can use '.'
folder_path = '/content/VIRUSTEXTCODE'  # Example: 'C:/Users/YourUser/Documents' or '/home/youruser/my_folder'

try:
    # Get a list of all entries (files and directories) in the specified path
    folder_contents = os.listdir(folder_path)

    print(f"Contents of '{folder_path}':")
    # Iterate through the list and print each item
    for item in folder_contents:
        print(item)

except FileNotFoundError:
    print(f"Error: The folder '{folder_path}' was not found.")
except Exception as e:
    print(f"An error occurred: {e}")

 ** Read Data From Text Files **

import os

# Virus files
virus_folder_path = "/content/VIRUSTEXTCODE/VIRUS CODES-NOTEPAD"
virus_file_names = []
virus_file_contents = []

for filename in os.listdir(virus_folder_path):
    if filename.endswith(".txt"):
        file_path = os.path.join(virus_folder_path, filename)
        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
            virus_file_names.append(filename)
            virus_file_contents.append(f.read())

# Non-virus files
non_virus_folder_path = "/content/VIRUSTEXTCODE/NON-VIRUS TEXT FILE"
non_virus_file_names = []
non_virus_file_contents = []

for filename in os.listdir(non_virus_folder_path):
    if filename.endswith(".txt"):
        file_path = os.path.join(non_virus_folder_path, filename)
        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
            non_virus_file_names.append(filename)
            non_virus_file_contents.append(f.read())

print("Virus files read:", len(virus_file_names))
print("Non-virus files read:", len(non_virus_file_names))

** TF-IDF Vectorization and Conversion **

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer()

# Fit and transform the virus and non-virus file contents
virus_tfidf_matrix = tfidf_vectorizer.fit_transform(virus_file_contents)
non_virus_tfidf_matrix = tfidf_vectorizer.transform(non_virus_file_contents)

# Get the feature names (words)
feature_names = tfidf_vectorizer.get_feature_names_out()

print("TF-IDF vectorization complete.")
print("Shape of virus TF-IDF matrix:", virus_tfidf_matrix.shape)
print("Shape of non-virus TF-IDF matrix:", non_virus_tfidf_matrix.shape)

** Converting Text Files To Numbers
import os
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder

# Read files from folders
virus_folder = "/content/VIRUSTEXTCODE/VIRUS CODES-NOTEPAD"
non_virus_folder = "/content/VIRUSTEXTCODE/NON-VIRUS TEXT FILE"

file_names = []
file_contents = []
labels = []  # 1 = Virus, 0 = Non-Virus

# Read virus files
for filename in os.listdir(virus_folder):
    if filename.endswith(".txt"):
        with open(os.path.join(virus_folder, filename), "r", encoding="utf-8", errors="ignore") as f:
            file_names.append(filename)
            file_contents.append(f.read())
            labels.append("Virus")

# Read non-virus files
for filename in os.listdir(non_virus_folder):
    if filename.endswith(".txt"):
        with open(os.path.join(non_virus_folder, filename), "r", encoding="utf-8", errors="ignore") as f:
            file_names.append(filename)
            file_contents.append(f.read())
            labels.append("Non-Virus")

print(f"Total Files Read: {len(file_names)}")

# Convert text to numeric features using TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(file_contents)  # TF-IDF matrix

# Convert labels to numeric values 
encoder = LabelEncoder()
y = encoder.fit_transform(labels)  # Virus=1, Non-Virus=0

# Create a DataFrame with TF-IDF features 
feature_names = vectorizer.get_feature_names_out()
tfidf_df = pd.DataFrame(X.toarray(), columns=feature_names)
tfidf_df["File Name"] = file_names
tfidf_df["Label"] = labels

# Display the DataFrame
print(tfidf_df.head())

** Installing Layzypredict Classifier
!pip install lazypredict

** Cleaning Data Set **

import re

def clean_text(text):
    # Keep only ASCII characters, remove any Unicode
    return re.sub(r'[^\x00-\x7F]+', ' ', text)

# Example: Clean virus and non-virus files
virus_files_cleaned = [clean_text(t) for t in virus_files]
non_virus_files_cleaned = [clean_text(t) for t in non_virus_files]

# Use the cleaned text for TF-IDF vectorization
all_texts = virus_files_cleaned + non_virus_files_cleaned

** Applying Classifier,Reading Text Files, Creating Labels, Converting Text to Numeric using TF-IDF and sparse matrix to DataFrame, 
Encoding labels,Train-Test Split, Run LazyPredict Classifier, Display all models **
 
import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from lazypredict.Supervised import LazyClassifier
from sklearn.feature_extraction.text import TfidfVectorizer

# Load Virus and Non-Virus Files
virus_folder = "/content/VIRUSTEXTCODE/VIRUS CODES-NOTEPAD"
non_virus_folder = "/content/VIRUSTEXTCODE/NON-VIRUS TEXT FILE"

virus_files = []
non_virus_files = []

# Read virus files
for filename in os.listdir(virus_folder):
    if filename.endswith(".txt"):
        with open(os.path.join(virus_folder, filename), "r", encoding="utf-8", errors="ignore") as f:
            virus_files.append(f.read())

# Read non-virus files
for filename in os.listdir(non_virus_folder):
    if filename.endswith(".txt"):
        with open(os.path.join(non_virus_folder, filename), "r", encoding="utf-8", errors="ignore") as f:
            non_virus_files.append(f.read())

# Create Labels
all_texts = virus_files + non_virus_files
labels = ["virus"] * len(virus_files) + ["non_virus"] * len(non_virus_files)

# Convert text to numeric features using TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(all_texts) # Use all_texts for fitting the vectorizer

# Convert sparse matrix to DataFrame
X_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())

# Encode labels (Virus=1, Non-Virus=0)
encoder = LabelEncoder()
y = encoder.fit_transform(labels)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.3, random_state=42) # Use X_df for splitting

# Run LazyPredict Classifier
clf = LazyClassifier(verbose=1, ignore_warnings=False, custom_metric=None)
models, predictions = clf.fit(X_train, X_test, y_train, y_test)

# Sort Results by Accuracy
models_sorted = models.sort_values(by="Accuracy", ascending=True)

# Display all models
print("\nTop Classifiers by Accuracy:\n")
print(models_sorted.head())  # show all models

** Bar Plot **

import matplotlib.pyplot as plt

# Sort models by Accuracy
models_sorted = models.sort_values(by="Accuracy", ascending=True)

# Select metrics to plot
metrics = ["Accuracy", "Balanced Accuracy", "ROC AUC", "F1 Score"]

# Plot each metric as a separate subplot
plt.figure(figsize=(15, 10))
for i, metric in enumerate(metrics, 1):
    plt.subplot(2, 2, i)  # 2x2 grid for 4 metrics
    bars = plt.barh(models_sorted.index, models_sorted[metric])
    plt.xlabel(metric)
    plt.title(f"Model Comparison - {metric}")
    plt.gca().invert_yaxis()

    # Add value labels on each bar
    for bar in bars:
        width = bar.get_width()
        plt.text(width + 0.01,                 # x position (slightly to the right of bar)
                 bar.get_y() + bar.get_height()/2,  # y position (centered)
                 f"{width:.2f}",               # format to 2 decimals
                 va='center')

plt.tight_layout()
plt.show()

** Box Plot **

import matplotlib.pyplot as plt
import numpy as np

# Sort models by Accuracy (just for consistency)
models_sorted = models.sort_values(by="Accuracy", ascending=False)

# Metrics to plot
metrics = ["Accuracy", "Balanced Accuracy", "ROC AUC", "F1 Score"]

# Prepare data for the box plot
box_data = [models_sorted[metric] for metric in metrics]

# Create the box plot
plt.figure(figsize=(12, 6))
box = plt.boxplot(box_data, labels=metrics, patch_artist=True,
                  boxprops=dict(facecolor="skyblue", color="blue"),
                  medianprops=dict(color="red"))

# Add grid and title
plt.title("Model Performance Comparison - Box Plot with Values")
plt.ylabel("Score")
plt.grid(axis="y", linestyle="--", alpha=0.7)

# Add median values on top of each box
for i, metric in enumerate(metrics):
    median_val = np.median(box_data[i])
    plt.text(i+1, median_val + 0.01, f"{median_val:.2f}",  # position and value
             ha='center', va='bottom', fontsize=10, color='black')

plt.show()

** Heat Map **

import seaborn as sns
import matplotlib.pyplot as plt

# Sort models by Accuracy (for better visualization order)
models_sorted = models.sort_values(by="Accuracy", ascending=False)

# Metrics to visualize
metrics = ["Accuracy", "Balanced Accuracy", "ROC AUC", "F1 Score"]

# Prepare data for the heatmap
heatmap_data = models_sorted[metrics]

# Create the heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(heatmap_data, annot=True, fmt=".2f", cmap="YlGnBu", cbar_kws={'label': 'Score'})

plt.title("Model Performance Heatmap")
plt.xlabel("Metrics")
plt.ylabel("Models")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
